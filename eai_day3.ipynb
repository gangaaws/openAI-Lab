{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+KCBoxIbfVTa7l7wTX5bz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gangaaws/openAI-Lab/blob/main/eai_day3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrhJXgqkuPOw",
        "outputId": "b4b4eec8-cf04-405b-81c5-97c05df9a98e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m286.7/803.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.11.1.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=cd5f2f0aad724309eaf30dec0a173d33512c84f2b2557090d9341c658435fc81\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: openai-whisper\n",
            "Successfully installed openai-whisper-20250625\n"
          ]
        }
      ],
      "source": [
        "!pip install openai-whisper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import urllib.request"
      ],
      "metadata": {
        "id": "XVNUqsggudbs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HYjH0k-rujb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUDIO_URL = \"https://github.com/fenago/whisper/raw/refs/heads/main/test_audio_files/dutch_the_netherlands.mp3\"\n",
        "AUDIO_FILE = \"dutch_the_netherlands.mp3\""
      ],
      "metadata": {
        "id": "kFNboBaQuyLt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(AUDIO_URL, AUDIO_FILE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeNCF8d0u0pf",
        "outputId": "5581fcee-b8f2-4af6-a260-172b8a60a8b1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('dutch_the_netherlands.mp3', <http.client.HTTPMessage at 0x7edc29e45160>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"medium\")"
      ],
      "metadata": {
        "id": "ApGa7oEBu7wY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_language_and_transcribe(audio_file: str, confidence_threshold: float = 0.5):\n",
        "    \"\"\"\n",
        "    Detect language and transcribe audio with confidence checking.\n",
        "\n",
        "    Args:\n",
        "        audio_file: Path to the audio file\n",
        "        confidence_threshold: Minimum confidence required (default: 0.5)\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (transcribed_text, detected_language, confidence)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load and prepare audio\n",
        "        audio = whisper.load_audio(audio_file)\n",
        "        audio = whisper.pad_or_trim(audio)\n",
        "        mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "        # Detect language\n",
        "        _, language_probs = model.detect_language(mel)\n",
        "        detected_language: str = max(language_probs, key=language_probs.get)\n",
        "        confidence: float = language_probs[detected_language]\n",
        "\n",
        "        # Clear printout of language detection\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"ðŸŽ¯ LANGUAGE DETECTION RESULT\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"Detected Language: {detected_language.upper()}\")\n",
        "        print(f\"Confidence Score: {confidence:.2%}\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        # Check confidence threshold\n",
        "        if confidence < confidence_threshold:\n",
        "            error_msg = (\n",
        "                f\"âš ï¸  Low confidence warning: Language detection confidence \"\n",
        "                f\"({confidence:.2%}) is below threshold ({confidence_threshold:.2%}). \"\n",
        "                f\"Detected language '{detected_language}' may be incorrect.\"\n",
        "            )\n",
        "            print(error_msg)\n",
        "            raise ValueError(error_msg)\n",
        "\n",
        "        # Transcribe with detected language\n",
        "        print(f\"\\nðŸ“ Transcribing in {detected_language}...\\n\")\n",
        "        options = whisper.DecodingOptions(language=detected_language, task=\"transcribe\")\n",
        "        result = whisper.decode(model, mel, options)\n",
        "\n",
        "        return result.text, detected_language, confidence\n",
        "\n",
        "    except ValueError as e:\n",
        "        # Re-raise confidence errors\n",
        "        raise e\n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ Error during language detection or transcription: {str(e)}\"\n",
        "        print(error_msg)\n",
        "        raise RuntimeError(error_msg) from e\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"EXAMPLE 1: Language Detection with Confidence Check\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "try:\n",
        "    text, language, confidence = detect_language_and_transcribe(\n",
        "        AUDIO_FILE,\n",
        "        confidence_threshold=0.5\n",
        "    )\n",
        "    print(f\"âœ… Transcription successful!\")\n",
        "    print(f\"Text: {text}\")\n",
        "except ValueError as e:\n",
        "    print(f\"âš ï¸  Continuing despite low confidence: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Unexpected error: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"EXAMPLE 2: Transcription with Translation to English\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "try:\n",
        "    result = model.transcribe(\n",
        "        AUDIO_FILE,\n",
        "        verbose=True,\n",
        "        language=\"nl\",  # Explicitly set Dutch\n",
        "        task=\"translate\",  # Translate to English\n",
        "    )\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"ðŸ“„ TRANSLATION RESULT\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Original Language: Dutch (nl)\")\n",
        "    print(f\"Translated Text: {result['text']}\")\n",
        "    print(\"=\"*50)\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Translation error: {e}\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"EXAMPLE 3: Top Language Predictions\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "try:\n",
        "    audio = whisper.load_audio(AUDIO_FILE)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "    _, language_probs = model.detect_language(mel)\n",
        "\n",
        "    # Sort and display top 3\n",
        "    sorted_languages = sorted(language_probs.items(), key=lambda x: x[1], reverse=True)\n",
        "    print(\"Top 3 Language Predictions:\")\n",
        "    for i, (lang, prob) in enumerate(sorted_languages[:3], 1):\n",
        "        print(f\"  {i}. {lang.upper()}: {prob:.2%}\")\n",
        "    print(\"=\"*50)\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error showing predictions: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKV3LQQR7xMi",
        "outputId": "f2d83c0f-e8f6-4db3-d7f1-75ae9970e722"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "EXAMPLE 1: Language Detection with Confidence Check\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "ðŸŽ¯ LANGUAGE DETECTION RESULT\n",
            "==================================================\n",
            "Detected Language: NL\n",
            "Confidence Score: 98.67%\n",
            "==================================================\n",
            "\n",
            "ðŸ“ Transcribing in nl...\n",
            "\n",
            "âœ… Transcription successful!\n",
            "Text: Hoi allemaal, dit is weer een testbestandje. Deze keer om te testen of de Nederlandse taal goed herkend gaat worden. Hierna kunnen we ook proberen deze tekst te laten vertalen naar het Engels om te zien hoe goed dat gaat. Ik ben benieuwd.\n",
            "\n",
            "==================================================\n",
            "EXAMPLE 2: Transcription with Translation to English\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:03.000]  Hey everyone, this is another test file.\n",
            "[00:03.000 --> 00:07.000]  This time to test whether the Dutch language will be recognized well.\n",
            "[00:07.000 --> 00:13.000]  After this we can also try to translate this text into English to see how well that goes.\n",
            "[00:13.000 --> 00:14.000]  I'm curious.\n",
            "\n",
            "==================================================\n",
            "ðŸ“„ TRANSLATION RESULT\n",
            "==================================================\n",
            "Original Language: Dutch (nl)\n",
            "Translated Text:  Hey everyone, this is another test file. This time to test whether the Dutch language will be recognized well. After this we can also try to translate this text into English to see how well that goes. I'm curious.\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "EXAMPLE 3: Top Language Predictions\n",
            "==================================================\n",
            "\n",
            "Top 3 Language Predictions:\n",
            "  1. NL: 98.67%\n",
            "  2. EN: 0.59%\n",
            "  3. DE: 0.50%\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TCb8M99D-TsB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}